{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install -q --upgrade openai\n",
    "# !pip uninstall openai\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from config import api_key_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"\")\n",
    "# client = OpenAI(api_key=api_key_openai)\n",
    "# model_name = \"gpt-4-0125-preview\"\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context_length</th>\n",
       "      <th>position</th>\n",
       "      <th>text</th>\n",
       "      <th>city1</th>\n",
       "      <th>label1</th>\n",
       "      <th>city2</th>\n",
       "      <th>label2</th>\n",
       "      <th>city3</th>\n",
       "      <th>label3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2k</td>\n",
       "      <td>0</td>\n",
       "      <td>Lambarka gaarka ah ee Dimishiq waa 6530597  L...</td>\n",
       "      <td>Dimishiq</td>\n",
       "      <td>6530597</td>\n",
       "      <td>Bratislava</td>\n",
       "      <td>9295259</td>\n",
       "      <td>Brussels</td>\n",
       "      <td>2793149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2k</td>\n",
       "      <td>25</td>\n",
       "      <td>Qaarada Afrika waxaa jira haween kaalin muuqat...</td>\n",
       "      <td>Lagos</td>\n",
       "      <td>6411637</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>1218893</td>\n",
       "      <td>Kampala</td>\n",
       "      <td>9968238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2k</td>\n",
       "      <td>50</td>\n",
       "      <td>Qaarada Afrika waxaa jira haween kaalin muuqat...</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>5076812</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>2333061</td>\n",
       "      <td>Amman</td>\n",
       "      <td>9329206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2k</td>\n",
       "      <td>75</td>\n",
       "      <td>Qaarada Afrika waxaa jira haween kaalin muuqat...</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>4031869</td>\n",
       "      <td>Ho Chi Minh</td>\n",
       "      <td>8243137</td>\n",
       "      <td>Sarajevo</td>\n",
       "      <td>1473906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8k</td>\n",
       "      <td>0</td>\n",
       "      <td>Lambarka gaarka ah ee Toronto waa 2666547  La...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>2666547</td>\n",
       "      <td>Paris</td>\n",
       "      <td>4480889</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>6132972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8k</td>\n",
       "      <td>25</td>\n",
       "      <td>Qaarada Afrika waxaa jira haween kaalin muuqat...</td>\n",
       "      <td>Yangon</td>\n",
       "      <td>2597969</td>\n",
       "      <td>Paris</td>\n",
       "      <td>2182273</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>5166663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8k</td>\n",
       "      <td>50</td>\n",
       "      <td>Qaarada Afrika waxaa jira haween kaalin muuqat...</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>2237697</td>\n",
       "      <td>Dimishiq</td>\n",
       "      <td>4085768</td>\n",
       "      <td>Helsinki</td>\n",
       "      <td>6268610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  context_length  position                                               text  \\\n",
       "0             2k         0   Lambarka gaarka ah ee Dimishiq waa 6530597  L...   \n",
       "1             2k        25  Qaarada Afrika waxaa jira haween kaalin muuqat...   \n",
       "2             2k        50  Qaarada Afrika waxaa jira haween kaalin muuqat...   \n",
       "3             2k        75  Qaarada Afrika waxaa jira haween kaalin muuqat...   \n",
       "4             8k         0   Lambarka gaarka ah ee Toronto waa 2666547  La...   \n",
       "5             8k        25  Qaarada Afrika waxaa jira haween kaalin muuqat...   \n",
       "6             8k        50  Qaarada Afrika waxaa jira haween kaalin muuqat...   \n",
       "\n",
       "           city1   label1          city2   label2      city3   label3  \n",
       "0       Dimishiq  6530597     Bratislava  9295259   Brussels  2793149  \n",
       "1          Lagos  6411637  San Francisco  1218893    Kampala  9968238  \n",
       "2        Chicago  5076812        Yerevan  2333061      Amman  9329206  \n",
       "3  San Francisco  4031869    Ho Chi Minh  8243137   Sarajevo  1473906  \n",
       "4        Toronto  2666547          Paris  4480889  Melbourne  6132972  \n",
       "5         Yangon  2597969          Paris  2182273    Yerevan  5166663  \n",
       "6         Sydney  2237697       Dimishiq  4085768   Helsinki  6268610  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets/Haystack_Needles/Incongruous/mBBC_2024/GPT4/English_needles.csv\n",
    "# dataset_path = \"datasets/Haystack_Needles/Incongruous/PaulGrahamEssays/GPT4/GPT4.csv\"\n",
    "\n",
    "data_path = \"datasets/Haystack_Needles/Incongruous\"\n",
    "\n",
    "needle_setting = \"3-needles\"\n",
    "# eng, vie, ind, swa, som\n",
    "haystack_lang = \"som\"\n",
    "prompt_lang = \"eng\"\n",
    "\n",
    "if model_name == \"gpt-4o\":\n",
    "    if needle_setting == \"1-needle\":\n",
    "        if haystack_lang == \"eng\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4o/English_needles.csv\"\n",
    "        elif haystack_lang == \"vie\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4o/Vietnamese_needles.csv\"\n",
    "        elif haystack_lang == \"ind\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4o/Indonesian_needles.csv\"\n",
    "        elif haystack_lang == \"swa\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4o/Swahili_needles.csv\"\n",
    "        elif haystack_lang == \"som\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4o/Somali_needles.csv\"\n",
    "            \n",
    "    elif needle_setting == \"2-needles\":\n",
    "        if haystack_lang == \"eng\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4o/English_needles.csv\"\n",
    "        elif haystack_lang == \"vie\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4o/Vietnamese_needles.csv\"\n",
    "        elif haystack_lang == \"ind\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4o/Indonesian_needles.csv\"\n",
    "        elif haystack_lang == \"swa\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4o/Swahili_needles.csv\"\n",
    "        elif haystack_lang == \"som\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4o/Somali_needles.csv\"\n",
    "            \n",
    "    elif needle_setting == \"3-needles\":\n",
    "        if haystack_lang == \"eng\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4o/English_needles.csv\"\n",
    "        elif haystack_lang == \"vie\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4o/Vietnamese_needles.csv\"\n",
    "        elif haystack_lang == \"ind\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4o/Indonesian_needles.csv\"\n",
    "        elif haystack_lang == \"swa\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4o/Swahili_needles.csv\"\n",
    "        elif haystack_lang == \"som\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4o/Somali_needles.csv\"\n",
    "    else:\n",
    "        print(\"------Invalid Needle Setting------\")\n",
    "            \n",
    "elif model_name == \"gpt-4-0125-preview\":\n",
    "    if needle_setting == \"1-needle\":\n",
    "        if haystack_lang == \"eng\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4/English_needles.csv\"\n",
    "        elif haystack_lang == \"vie\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4/Vietnamese_needles.csv\"\n",
    "        elif haystack_lang == \"ind\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4/Indonesian_needles.csv\"\n",
    "        elif haystack_lang == \"swa\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4/Swahili_needles.csv\"\n",
    "        elif haystack_lang == \"som\":\n",
    "            dataset_path = f\"{data_path}/1-Needle/mBBC_2024/GPT4/Somali_needles.csv\"\n",
    "            \n",
    "    elif needle_setting == \"2-needles\":\n",
    "        if haystack_lang == \"eng\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4/English_needles.csv\"\n",
    "        elif haystack_lang == \"vie\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4/Vietnamese_needles.csv\"\n",
    "        elif haystack_lang == \"ind\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4/Indonesian_needles.csv\"\n",
    "        elif haystack_lang == \"swa\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4/Swahili_needles.csv\"\n",
    "        elif haystack_lang == \"som\":\n",
    "            dataset_path = f\"{data_path}/2-Needles/GPT4/Somali_needles.csv\"\n",
    "            \n",
    "    elif needle_setting == \"3-needles\":\n",
    "        if haystack_lang == \"eng\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4/English_needles.csv\"\n",
    "        elif haystack_lang == \"vie\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4/Vietnamese_needles.csv\"\n",
    "        elif haystack_lang == \"ind\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4/Indonesian_needles.csv\"\n",
    "        elif haystack_lang == \"swa\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4/Swahili_needles.csv\"\n",
    "        elif haystack_lang == \"som\":\n",
    "            dataset_path = f\"{data_path}/3-Needles/GPT4/Somali_needles.csv\"\n",
    "\n",
    "    else:\n",
    "        print(\"------Invalid Needle Setting------\")\n",
    "\n",
    "# eng_needles = pd.read_csv(dataset_path)\n",
    "eng_needles = pd.read_csv(dataset_path)\n",
    "eng_needles.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1-Needle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haystack_lang = \"vie\"\n",
    "# prompt_lang = \"eng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt4_inference_one_needle(df, model_name, max_tokens, prompt_lang):\n",
    "    generated_text = []\n",
    "    \n",
    "    for text in df[\"text\"]:\n",
    "        # prompt = f\"{text}\\nHere is the magic number:\"\n",
    "\n",
    "        if prompt_lang == \"eng\":\n",
    "            prompt = f'''\n",
    "                You are a helpful AI bot that answers questions for a user. Keep your response short and direct.\n",
    "                The following is a set of context and a question that will relate to the context. \n",
    "                #CONTEXT\n",
    "                {text}\n",
    "                #ENDCONTEXT\n",
    "                \n",
    "                #QUESTION\n",
    "                What is the special magic {{}} number? Don't give information outside the document or repeat your findings. If the\n",
    "                information is not available in the context respond UNANSWERABLE.\n",
    "            '''\n",
    "        elif prompt_lang == \"vie\":\n",
    "            prompt = f'''\n",
    "                Bạn là một bot AI hữu ích có khả năng trả lời các câu hỏi cho người dùng. Dùng câu trả lời ngắn gọn và trực tiếp.\n",
    "                Sau đây là một vài bối cảnh và một câu hỏi sẽ liên quan đến bối cảnh.\n",
    "                #CONTEXT\n",
    "                {text}\n",
    "                #ENDCONTEXT\n",
    "        \n",
    "                #QUESTION\n",
    "                Số {{}} ma thuật đặc biệt là gì? Đừng cung cấp thông tin bên ngoài tài liệu hoặc lặp lại những phát hiện của bạn. Nếu\n",
    "                thông tin không có sẵn trong ngữ cảnh trả lời KHÔNG THỂ TRẢ LỜI.\n",
    "            '''\n",
    "        elif prompt_lang == \"ind\":\n",
    "            prompt = f'''\n",
    "                Kamu merupakan bot AI yang sangat membantu dalam menjawab pertanyaan pengguna. Pastikan jawabanmu tetap singkat dan tidak berbelit-belit. \n",
    "                Berikut ini adalah satu set konteks dan pertanyaan yang akan berkaitan dengan konteks tersebut.\n",
    "                #CONTEXT\n",
    "                {text}\n",
    "                #ENDCONTEXT\n",
    "        \n",
    "                #QUESTION\n",
    "                Berapa nomor ajaib khusus {{}} untuk? Jangan memberikan informasi di luar dokumen atau mengulangi yang kamu temukan. \n",
    "                Jika informasinya tidak tersedia di dalam konteks tersebut, jawablah dengan TIDAK DAPAT DIJAWAB.\n",
    "            '''\n",
    "        elif prompt_lang == \"som\":\n",
    "            prompt = f'''\n",
    "                Waxaad tahay bot AI waxtar leh oo ka jawaaba su'aalaha macmiilka. Ka dhig jawaabtaada mid gaaban oo toos ah. \n",
    "                Kuwan soo socdaa waa qoraala kooban iyo su'aal la xidhiidhi doonta macnaha guud.\n",
    "                #CONTEXT\n",
    "                {text}\n",
    "                #ENDCONTEXT\n",
    "        \n",
    "                #QUESTION\n",
    "                Waa maxay lambarka gaarka ah ee {{}}? Ha bixin macluumaad ka baxsan dukumeentiga ama ha ku celin natiijooyinkaaga. \n",
    "                Haddii macluumaadka aan laga heli karin macnaha guud waxaad ku jawaabtaa LAGAMA JAWAABI KARO\n",
    "            '''\n",
    "        elif prompt_lang == \"swa\":\n",
    "            prompt = f'''\n",
    "                Wewe ni roboti ya AI inayesaidia kujibu maswali kwa mtumiaji. Endelea na majibu mafupi na moja kwa moja. \n",
    "                Yafuatayo ni muktadha na swali litakalohusiana na muktadha.\n",
    "                #CONTEXT\n",
    "                {text}\n",
    "                #ENDCONTEXT\n",
    "        \n",
    "                #QUESTION\n",
    "                Nambari {{}} maalum ni ipi ? Usitoe habari nje ya hati au kurudia matokeo yako. \n",
    "                Ikiwa habari haipatikani katika muktadha, jibu, HAKUNA MAJIBU.\n",
    "            '''\n",
    "        elif prompt_lang == \"aze\":\n",
    "            prompt = f'''\n",
    "                Sən istifadəçinin suallarına cavab verən faydalı bir AI botsan. Qısa və birbaşa cavab ver. \n",
    "                Aşağıda bir kontekst toplusu və kontekstlə bağlı bir sual verilib.\n",
    "                #CONTEXT\n",
    "                {text}\n",
    "                #ENDCONTEXT\n",
    "        \n",
    "                #QUESTION\n",
    "                Xüsusi sehrli {{}} nömrəsi nədir? Sənəddən kənar məlumat vermə və ya tapdığın məlumatı təkrar etmə. \n",
    "                Əgər məlumat kontekstdə mövcud deyilsə, CAVABLANA BİLMƏYƏN kimi cavab ver.\n",
    "            '''\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            max_tokens=max_tokens,\n",
    "            messages=[\n",
    "                # {\"role\": \"system\", \"content\": \"You are a fact finder.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        generated_text.append(response.choices[0].message.content)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "def evaluate(row):\n",
    "    if str(row['label']) in row['generated_text']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# eng_needles.iloc[:1]\n",
    "generated_text = gpt4_inference_one_needle(df=eng_needles, \n",
    "                                model_name=model_name, \n",
    "                                max_tokens=50,\n",
    "                                prompt_lang = prompt_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_needles['generated_text'] = generated_text\n",
    "eng_needles['found'] = eng_needles.apply(evaluate, axis=1)\n",
    "# eng_needles.to_csv(f\"outputs/Incongruous/1-Needle/mBBC_2024/GPT4/gpt-4_{haystack_lang}_{prompt_lang}_fixed.csv\", index=False)\n",
    "eng_needles.to_csv(f\"outputs/Incongruous/1-Needle/mBBC_2024/GPT4o/gpt-4o_{haystack_lang}_{prompt_lang}_fixed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2-Needle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt4_inference_two_needles_v2(df, model_name, max_tokens):\n",
    "    generated_text = []\n",
    "    \n",
    "    for text in df[\"text\"]:\n",
    "        prompt = f'''\n",
    "        You are a helpful AI bot that answers questions for a user. Keep your response short and direct.\n",
    "        The following is a set of context and a question that will relate to the context. \n",
    "        #CONTEXT\n",
    "        {text}\n",
    "        #ENDCONTEXT\n",
    "        \n",
    "        #QUESTION\n",
    "        What is the larger magic number? Don't give information outside the document or repeat your findings. \n",
    "        If the information is not available in the context respond UNANSWERABLE.\n",
    "        '''\n",
    "    \n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            max_tokens=max_tokens,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        generated_text.append(response.choices[0].message.content)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# eng_needles = eng_needles.iloc[:1]\n",
    "max_tokens = 50\n",
    "generated_text = gpt4_inference_two_needles_v2(df=eng_needles,\n",
    "                                model_name=model_name, \n",
    "                                max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_2needle_v2(df):    \n",
    "    df['bigger_label'] = df.apply(lambda row: row['label1'] if row['label1'] > row['label2'] else row['label2'], axis=1)\n",
    "    df['found'] = df['bigger_label'].astype(str).apply(lambda x: df['generated_text'].str.contains(x).any()).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_needles['generated_text'] = generated_text\n",
    "# eng_needles['found'] = eng_needles.apply(evaluate, axis=1)\n",
    "eng_needles = evaluate_2needle_v2(eng_needles)\n",
    "\n",
    "if model_name == \"gpt-4-0125-preview\":\n",
    "    eng_needles.to_csv(f\"outputs/Incongruous/2-Needles/mBBC_2024/GPT4/gpt-4_{haystack_lang}_{prompt_lang}_number.csv\", index=False)\n",
    "elif model_name == \"gpt-4o\":\n",
    "    eng_needles.to_csv(f\"outputs/Incongruous/2-Needles/mBBC_2024/GPT4o/gpt-4_{haystack_lang}_{prompt_lang}_number.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Needles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T07:43:49.050790Z",
     "start_time": "2024-03-13T07:43:49.047738Z"
    }
   },
   "outputs": [],
   "source": [
    "def gpt4_inference_three_needles_v2(df, model_name, max_tokens):\n",
    "    generated_text = []\n",
    "    \n",
    "    for text in df[\"text\"]:\n",
    "        prompt = f'''\n",
    "        You are a helpful AI bot that answers questions for a user. Keep your response short and direct.\n",
    "        The following is a set of context and a question that will relate to the context. \n",
    "        #CONTEXT\n",
    "        {text}\n",
    "        #ENDCONTEXT\n",
    "        \n",
    "        #QUESTION\n",
    "        What is the largest magic number? Don't give information outside the document or repeat your findings. \n",
    "        If the information is not available in the context respond UNANSWERABLE.\n",
    "        '''\n",
    "    \n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            max_tokens=max_tokens,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        generated_text.append(response.choices[0].message.content)\n",
    "\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# eng_needles = eng_needles.iloc[:1]\n",
    "max_tokens = 50\n",
    "generated_text = gpt4_inference_three_needles_v2(df=eng_needles,\n",
    "                                model_name=model_name, \n",
    "                                max_tokens=max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_3needle_v2(df):\n",
    "    df['bigger_label'] = df.apply(lambda row: max(row['label1'], row['label2'], row['label3']), axis=1)\n",
    "    df['found'] = df['bigger_label'].astype(str).apply(lambda x: df['generated_text'].str.contains(x).any()).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T07:45:51.362473Z",
     "start_time": "2024-03-13T07:45:51.355730Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# haystack_lang = \"eng\"\n",
    "# # prompt_lang = \"eng\"\n",
    "\n",
    "eng_needles['generated_text'] = generated_text\n",
    "# eng_needles = pd.read_csv(f\"outputs/Incongruous/3-Needles/mBBC_2024/GPT4/gpt-4_{haystack_lang}_{prompt_lang}_number.csv\")\n",
    "eng_needles = evaluate_3needle_v2(eng_needles)\n",
    "\n",
    "if model_name == \"gpt-4-0125-preview\":\n",
    "    eng_needles.to_csv(f\"outputs/Incongruous/3-Needles/mBBC_2024/GPT4/gpt-4_{haystack_lang}_{prompt_lang}_number_v2.csv\", index=False)\n",
    "elif model_name == \"gpt-4o\":\n",
    "    eng_needles.to_csv(f\"outputs/Incongruous/3-Needles/mBBC_2024/GPT4o/gpt-4_{haystack_lang}_{prompt_lang}_number_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-13T07:45:53.803532Z",
     "start_time": "2024-03-13T07:45:53.797514Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
